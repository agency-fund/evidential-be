version: '3'
output: prefixed
vars:
  XNGIN_LOCALDB_DSN: "postgresql://postgres:postgres@localhost:5499/xngin?sslmode=disable"
env:
  # Disable Atlas telemetry.
  ATLAS_NO_ANON_TELEMETRY: "true"
  DO_NOT_TRACK: "1"

  # Google will redirect to this URL upon successful authentication. This URL is served by the frontend application
  # and the GoogleAuthProvider component will intercept the query arguments and handle them.
  GOOGLE_OIDC_REDIRECT_URI: "http://localhost:3000/"

  # These values are configured in the xngin-development-dc project and should be used in development environments:
  # https://console.cloud.google.com/apis/credentials?organizationId=256829878972&project=xngin-development-dc.
  GOOGLE_OIDC_CLIENT_ID: "222213100775-qa1ajcrk48il70itcbdcvgr9ib5t08uf.apps.googleusercontent.com"

  # These values are configured in the evidential-live project and should only be used when validating the
  # production environments:
  # https://console.cloud.google.com/auth/clients?project=evidential-live
  #GOOGLE_OIDC_CLIENT_ID: "314428509782-j8fgiq5dvoic01432s2bcu3isinc9kam.apps.googleusercontent.com"
  #GOOGLE_OIDC_REDIRECT_URI: "http://localhost:3000/"

  # These are values used in the xngin.railway.settings.json and are present for when testing the Railway configs.
  # (optional)
  DWH_PGHOST: "127.0.0.1"
  DWH_PGPASSWORD: "pgpass"
  DWH_PGPORT: "5632"
  DWH_PGUSER: "pguser"
  CUSTOMER_API_TOKEN: ""
  CUSTOMER_DWH_PASSWORD: ""

  # Ask SQLAlchemy to print the generated SQL statements.
  ECHO_SQL: "true"

  # Publish the OpenAPI spec for the admin and OIDC APIs
  XNGIN_PUBLISH_ALL_DOCS: "true"

  # Generally useful settings.
  XNGIN_SETTINGS: "src/xngin/apiserver/testdata/xngin.testing.settings.json"
  XNGIN_DEBUG: "true"
tasks:
  start:
    desc: "Starts apiserver locally with settings compatible with local dash dev server (using sqlite)."
    interactive: true
    dotenv:
      # Populate BQ_SERVICE_ACCOUNT (optional) and GOOGLE_OIDC_CLIENT_SECRET (optional).
      - .env
    env:
      # Admin API settings. These need to be set for interaction with the dash web UI.
      # Also see instructions for .env above.
      ENABLE_ADMIN: "true"
      ENABLE_OIDC: "true"

    cmds:
      - uv run fastapi dev src/xngin/apiserver/main.py
  start-with-local-pg:
    desc: "Starts apiserver locally with settings compatible with local dash dev server (using PostgreSQL)"
    interactive: true
    dotenv:
      # Populate BQ_SERVICE_ACCOUNT (optional) and GOOGLE_OIDC_CLIENT_SECRET (optional).
      - .env
    env:
      XNGIN_DB: "{{.XNGIN_LOCALDB_DSN}}"

      # Admin API settings. These need to be set for interaction with the dash web UI.
      # Also see instructions for .env above.
      ENABLE_ADMIN: "true"
      ENABLE_OIDC: "true"
    cmds:
      # Ensure the localpg server is running and has an "xngin" database. If the database doesn't already exist,
      # have Atlas create the tables so that subsequent table migrations behave as expected.
      - ./tools/localpg.py --allow-existing -d --wait --create-db xngin --if-created "uv run task apply-migrations-pg"
      - task bootstrap-dwh-local-pg || /bin/true
      - uv run fastapi dev src/xngin/apiserver/main.py
  bootstrap-dwh-local-pg:
    desc: "Bootstraps the localpg server with a sample data warehouse."
    interactive: true
    cmds:
      - uv run xngin-cli create-testing-dwh --dsn 'postgresql+psycopg://postgres:postgres@localhost:5499/dwh?sslmode=disable' --hacks
  test:
    desc: "Runs unit tests"
    interactive: true
    cmds:
      - uv run pytest
  update-api-tests:
    desc: "Run the API tests and update the expected responses."
    interactive: true
    env:
      UPDATE_API_TESTS: "1"
    cmd: uv run pytest src/xngin/apiserver/test_api.py
  test-pgintegration:
    desc: "Runs unit tests w/local postgres support"
    interactive: true
    cmds:
      - ./tools/localpg.py --allow-existing -d --wait
      - uv run pytest -m 'pgintegration or not integration'
  make-migrations:
    desc: "Build Postgres migrations"
    cmds:
      - uv run atlas migrate diff --env sa_postgres && git add migrations
  apply-migrations-pg:
    desc: "Apply Postgres migrations locally (requires localpg instance to be running, to have an xngin database, and to have been previously migrated)"
    cmds:
      - uv run atlas migrate diff --env sa_postgres
      - uv run atlas migrate apply --env sa_postgres --url '{{.XNGIN_LOCALDB_DSN}}'
  apply-migrations-sqlite:
    desc: "Apply sqlite migrations locally"
    cmd: |
      # Generate the migration files to ensure that they are up to date
      uv run atlas migrate diff --env sa_sqlite
      # If the apiserver created the database, there will not be any migration data; therefore, we pass a --baseline
      # flag to get that created.
      sqlite3 xngin.db .tables | grep -q "atlas_schema_revisions" \
        && uv run atlas migrate apply --env sa_sqlite --url sqlite://xngin.db \
        || uv run atlas migrate apply --env sa_sqlite --url sqlite://xngin.db --baseline $(ls -t migrations/sa_sqlite | grep .sql | sort -n | cut -f1 -d. | head -1)
