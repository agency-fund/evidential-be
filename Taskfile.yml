version: '3'
output: prefixed
vars:
  # App database for the local dev environment (see tasks: start, apply-migrations)
  XNGIN_DEVAPPDB_NAME: '{{default "xngin" .XNGIN_DEVAPPDB_NAME}}'

  # The DSN passed to SQLAlchemy when connecting to the development xngin database.
  XNGIN_DEVAPP_DSN: "postgresql+psycopg://postgres:postgres@localhost:5499/{{.XNGIN_DEVAPPDB_NAME}}?sslmode=disable"

  # The DSN used for managing the Postgres instance. This refers to the postgres database because it reliably exists,
  # whereas the xngin database does not.
  XNGIN_LOCALPG_DSN: "postgresql://postgres:postgres@localhost:5499/postgres?sslmode=disable"

  # The DSN used for anything using a plain db URI, without +driver syntax, e.g. Atlas migrations of the xngin database,
  # or using psycopg directly in the task queue.
  XNGIN_DEVAPP_STANDARD_DSN: '{{replace "+psycopg" "" .XNGIN_DEVAPP_DSN}}'
  XNGIN_DEVAPP_MIGRATIONS_LINT_DSN: "postgresql://postgres:postgres@localhost:5499/migration_lint?sslmode=disable"

env:

  # Disable Atlas telemetry.
  ATLAS_NO_ANON_TELEMETRY: "true"
  DO_NOT_TRACK: "1"

  # Allow connecting to data warehouses residing in private IP ranges.
  ALLOW_CONNECTING_TO_PRIVATE_IPS: "1"

  # Google will redirect to this URL upon successful authentication. This URL is served by the frontend application
  # and the GoogleAuthProvider component will intercept the query arguments and handle them.
  GOOGLE_OIDC_REDIRECT_URI: "http://localhost:3000/"

  # These values are configured in the xngin-development-dc project and should be used in development environments:
  # https://console.cloud.google.com/apis/credentials?organizationId=256829878972&project=xngin-development-dc.
  GOOGLE_OIDC_CLIENT_ID: "222213100775-qa1ajcrk48il70itcbdcvgr9ib5t08uf.apps.googleusercontent.com"

  # These values are configured in the evidential-live project and should only be used when validating the
  # production environments:
  # https://console.cloud.google.com/auth/clients?project=evidential-live
  #GOOGLE_OIDC_CLIENT_ID: "314428509782-j8fgiq5dvoic01432s2bcu3isinc9kam.apps.googleusercontent.com"
  #GOOGLE_OIDC_REDIRECT_URI: "http://localhost:3000/"

  # Configure SQLAlchemy to log the generated SQL statements used on customer DWH via its own logger.
  ECHO_SQL: "false"

  # Configure SQLAlchemy to log the generated SQL statements used on xngin app database via its own logger.
  ECHO_SQL_APP_DB: "false"

  # Use a concise log line formatter for improved readability in the terminal.
  FRIENDLY_DEV_LOGGING: "true"

  # Set DEBUG_LOGGING to true to display detailed information about logging configuration to stdout. Only set this to
  # true if you are debugging issues with logs.
  DEBUG_LOGGING: "false"

  # Configure customlogging.py to log dwh SQL to the custom log.
  LOG_SQL: "true"

  # Configure customlogging.py to log app SQL to the custom log.
  LOG_SQL_APP_DB: "false"

  # Publish the OpenAPI spec for the admin and OIDC APIs
  XNGIN_PUBLISH_ALL_DOCS: "true"

  # Data warehouse available for use by the local dev environment (see task bootstrap-dwh-database) and also referenced
  # by unit tests via xngin.testing.settings.json. It is bootstrapped with the testing datawarehouse when
  # `task start` is used.
  XNGIN_DEVDWH_DSN: "postgresql+psycopg://postgres:postgres@localhost:5499/dwh?sslmode=disable"

  # Datasource for tests of the xngin app database that use the xngin_db_session dependency or the xngin_session
  # test fixture.
  DATABASE_URL_FOR_TEST: "postgresql+psycopg://postgres:postgres@localhost:5499/test_xngin?sslmode=disable"

  # Datasource for the tests using the xngin.apiserver.dwh.test_queries.fixture_queries_session fixture.
  XNGIN_QUERIES_TEST_URI: "postgresql+psycopg://postgres:postgres@localhost:5499/test_queries?sslmode=disable"

  # XNGIN_PUBLIC_HOSTNAME defines the base hostname (and optional port) we use when constructing URLs to send to
  # external systems (such as via outbound webhooks).
  XNGIN_PUBLIC_PROTOCOL: "http"
  XNGIN_PUBLIC_HOSTNAME: "localhost:8000"
tasks:
  install-atlas:
    interactive: true
    status:
      - which atlas
    cmd: curl -sSf https://atlasgo.sh | sh
  install-uv:
    interactive: true
    status:
      - which uv
    cmd: curl -LsSf https://astral.sh/uv/install.sh | sh
  check-git-lfs:
    status:
      - which git-lfs
    cmds:
      - echo -e "⚠️ This machine does not have a git-lfs binary available. \nPlease install from https://git-lfs.com/ \nthen run 'git lfs install' and 'git lfs pull' from this repo."
  check-pg-config:
    platforms:
      - linux
    status:
      - which pg_config
    cmds:
      - "echo ⚠️ This machine does not have a pg_config binary available."
      - "echo To fix, run: sudo apt install libpq-dev."
  check-docker:
    status:
      - which docker
    cmds:
      - "echo ⚠️ This machine does not have a docker binary available. Please install Docker."
  install-dependencies:
    desc: "Install Atlas and UV and check on dependencies."
    prompt: "This command will install CLI tools (Atlas and uv) and create or update a Python virtual environment. This may add binaries to your $PATH, and also prompt you for your sudo password. Do you wish to proceed?"
    cmds:
      - task: install-atlas
      - task: install-uv
      - task: check-git-lfs
      - task: check-pg-config
      - cmd: |
          atlas version
          uv version
          task --version
      - cmd: uv sync --compile-bytecode
      - task: check-docker
  start-localpg:
    desc: "Starts a local Postgres server."
    run: once
    cmds:
      - ./tools/localpg.py --allow-existing -d --wait --create-db {{.XNGIN_DEVAPPDB_NAME}}
  bootstrap-dwh-database:
    desc: "Loads a sample data warehouse into the localpg server."
    interactive: true
    deps:
      - start-localpg
    cmds:
      - uv run xngin-cli create-testing-dwh --dsn "$XNGIN_DEVDWH_DSN" --allow-existing --create-db
  bootstrap-app-database:
    interactive: true
    desc: >-
      Ensure the localpg server is running and has an "xngin" database. If the database doesn't already exist, it will
      be created, and Atlas will create the tables as described by migration files.
    deps:
      - start-localpg
    cmds:
      - task: apply-migrations
  start:
    desc: "Starts apiserver locally with settings compatible with local dash dev server."
    interactive: true
    dotenv:
      # Populate BQ_SERVICE_ACCOUNT (optional) and GOOGLE_OIDC_CLIENT_SECRET (optional).
      - .env
    env:
      DATABASE_URL: "{{.XNGIN_DEVAPP_DSN}}"
    deps:
      - bootstrap-dwh-database
      - bootstrap-app-database
    cmds:
      - uv run fastapi dev src/xngin/apiserver/main.py
  start-airplane:
    desc: "Like start, but runs the backend in airplane mode. All Admin API interactions will be authenticated as testing@example.com automatically."
    interactive: true
    env:
      AIRPLANE_MODE: "true"
    cmds:
      - task start
  test-coverage:
    desc: "Runs unit tests and generates a coverage report."
    summary: |
      Runs all the unit tests and generates a coverage report. Pass additional arguments to pytest after a --. Example:

      task test-coverage -- src/xngin/apiserver/routers/admin/test_admin.py # run a single test file
      task test-coverage -- -k tests_matching_some_string_expression -rA    # run subset of tests, show all output in summary
      task test-coverage -- -m integration                                  # run tests annotated with @pytest.mark.integration
    interactive: true
    env:
      DATABASE_URL: "{{.DATABASE_URL_FOR_TEST}}"
    deps:
      - bootstrap-dwh-database
    cmds:
      - uv run coverage run -m pytest {{.CLI_ARGS}}
      - uv run coverage html
      - uv run coverage report
      - echo "Open the HTML report at file://{{.USER_WORKING_DIR}}/htmlcov/index.html"
  test-coverage-airplane:
    desc: "Run unit tests and generate a coverage report (in airplane mode)."
    interactive: true
    env:
      AIRPLANE_MODE: "true"
    cmds:
      - task test-coverage
  test:
    desc: "Runs unit tests"
    summary: |
      Runs all the unit tests. Pass additional arguments to pytest after a --. Example:

      task test -- src/xngin/apiserver/routers/admin/test_admin.py # run a single test file
      task test -- -k tests_matching_some_string_expression -rA    # run subset of tests, show all output in summary
      task test -- -m integration                                  # run tests annotated with @pytest.mark.integration
    interactive: true
    env:
      DATABASE_URL: "{{.DATABASE_URL_FOR_TEST}}"
    deps:
      - bootstrap-dwh-database
    cmds:
      - uv run pytest {{.CLI_ARGS}}
  test-airplane:
    desc: "Run unit tests (in airplane mode)."
    interactive: true
    env:
      AIRPLANE_MODE: "true"
    cmds:
      - task test
  test-integration:
    desc: "Runs Google integration tests. Requires GOOGLE_APPLICATION_CREDENTIALS environment variable to be set."
    interactive: true
    env:
      DATABASE_URL: "{{.DATABASE_URL_FOR_TEST}}"
    cmds:
      - uv run pytest -m integration
  update-api-tests:
    desc: "Run the API tests and update the expected responses."
    interactive: true
    env:
      UPDATE_API_TESTS: "1"
      DATABASE_URL: "{{.DATABASE_URL_FOR_TEST}}"
    deps:
      - bootstrap-dwh-database
    cmd: uv run pytest -m xurl
  make-migrations:
    desc: "Build Postgres migrations"
    interactive: true
    cmd: |
      uv run atlas migrate diff --env sa_postgres && git add migrations
      echo 💡 If you modify the migration file afterwards, you should re-hash it: task hash-migrations
  hash-migrations:
    desc: "Rehash your migration file (see atlas.sum) if you had to modify the generated migration file afterwards, e.g. to add a custom backfill."
    cmds:
      - uv run atlas migrate hash --env sa_postgres
  migration-reset:
    desc: "Drop the local development database's schema, tables, and Atlas migration state. Use this when your local database is out of sync with merged migrations."
    cmds:
      - uv run atlas schema clean --env sa_postgres --url "{{.XNGIN_DEVAPP_STANDARD_DSN}}"
      - psql "{{.XNGIN_DEVAPP_STANDARD_DSN}}" -c "CREATE SCHEMA public;"
      - task: apply-migrations
  migration-lint:
    desc: "Lint the latest migration file. Add 'LATEST=N' to lint the N most recent files."
    vars:
      LATEST: "{{default 1 .LATEST}}"
    cmds:
      - psql "{{.XNGIN_DEVAPP_STANDARD_DSN}}" -c "CREATE DATABASE migration_lint;" || true
      - >
        uv run atlas migrate lint --dir "file://migrations/sa_postgres/"
        --latest {{.LATEST}} --dev-url "{{.XNGIN_DEVAPP_MIGRATIONS_LINT_DSN}}"
  migration-status:
    desc: "Provides in-depth information about the migration status of the connected database. Useful for debugging migration issues."
    cmds:
      - uv run atlas migrate status --env sa_postgres --url "{{.XNGIN_DEVAPP_STANDARD_DSN}}"
  make-manual-migration:
    desc: "Create and edit a new migration file manually. Use this to manually adjust values in the database."
    interactive: true
    cmds:
      - uv run atlas migrate new --env sa_postgres --edit
  down-migration:
    desc: "Go back a version in the migration history. Note that it include pre-migration checks to ensure data isn't deleted and tables are empty, so you may have to manually do some prep for the reversion. See https://atlasgo.io/versioned/down"
    cmds:
      - uv run atlas migrate down --env sa_postgres --url "{{.XNGIN_DEVAPP_STANDARD_DSN}}"
  apply-migrations:
    desc: "Apply Postgres migrations locally (requires localpg instance to be running, to have an xngin database, and to have been previously migrated)"
    cmds:
      - uv run atlas migrate diff --env sa_postgres
      - >
        uv run atlas migrate apply --env sa_postgres --url "{{.XNGIN_DEVAPP_STANDARD_DSN}}" ||
          (echo "⚠️ Something is awry with your development database. This can happen when switching branches. You can
            reset the database to the default state by running \"task drop-databases\"."; exit 1)
  create-user:
    desc: "Create a user: task create-user -- username@example.com"
    interactive: true
    deps:
      - bootstrap-app-database
    env:
      DATABASE_URL: "{{.XNGIN_DEVAPP_DSN}}"
    cmd: |
      uv run xngin-cli add-user
  start-tq:
    desc: "Start the task queue."
    env:
      DATABASE_URL: "{{.XNGIN_DEVAPP_STANDARD_DSN}}"  # tq uses psycopg3 directly (not SQLAlchemy).
    deps:
      - bootstrap-app-database
    cmd: uv run xngin-tq
  psql:
    desc: "Start interactive psql"
    interactive: true
    deps:
      - bootstrap-app-database
    cmd: psql "{{.XNGIN_DEVAPP_STANDARD_DSN}}"
  drop-databases:
    desc: "Forcibly remove the local development databases."
    interactive: true
    cmds:
      - psql "{{.XNGIN_LOCALPG_DSN}}" -c "DROP DATABASE dwh WITH (FORCE);" || true
      - psql "{{.XNGIN_LOCALPG_DSN}}" -c "DROP DATABASE migration_lint WITH (FORCE);" || true
      - psql "{{.XNGIN_LOCALPG_DSN}}" -c "DROP DATABASE test_xngin WITH (FORCE);" || true
      - psql "{{.XNGIN_LOCALPG_DSN}}" -c "DROP DATABASE {{.XNGIN_DEVAPPDB_NAME}} WITH (FORCE);" || true
